# Breast Cancer Detection using Machine Learning (SVM and Decision Tree)
# Full version with all visualizations and model comparisons
# Simplified single-file implementation (no directories)

# -------------------------------
# 1. Import Libraries
# -------------------------------
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier, plot_tree

# -------------------------------
# 2. Load Dataset
# -------------------------------
df = pd.read_csv("C:/Users/geral/Documents/archive/data.csv")
print("Dataset shape:", df.shape)
print(df.head())

# -------------------------------
# 3. Data Cleaning
# -------------------------------
# Drop unnecessary columns
df.drop(['id', 'Unnamed: 32'], axis=1, inplace=True)

# Encode target variable
df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})

# Check for missing values
print("\nMissing values per column:\n", df.isnull().sum())

# -------------------------------
# 4. Exploratory Data Analysis
# -------------------------------
print("\nDataset summary statistics:\n", df.describe())

# Diagnosis Distribution Plot
sns.countplot(x='diagnosis', data=df, palette='coolwarm')
plt.title("Diagnosis Distribution (0 = Benign, 1 = Malignant)")
plt.xlabel("Diagnosis")
plt.ylabel("Count")
plt.savefig('diagnosis_distribution.png')
plt.show()

# Correlation Heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.savefig('correlation_heatmap.png')
plt.show()

# -------------------------------
# 5. Data Preparation
# -------------------------------
X = df.drop('diagnosis', axis=1)
y = df['diagnosis']

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# -------------------------------
# 6. Model Training
# -------------------------------
svm_model = SVC(kernel='linear', probability=True, random_state=42)
svm_model.fit(X_train, y_train)
svm_pred = svm_model.predict(X_test)

dt_model = DecisionTreeClassifier(max_depth=4, random_state=42)
dt_model.fit(X_train, y_train)
dt_pred = dt_model.predict(X_test)

# -------------------------------
# 7. Model Evaluation Function
# -------------------------------
def evaluate_model(name, y_true, y_pred, model):
    print(f"\n--- {name} Evaluation ---")
    acc = accuracy_score(y_true, y_pred)
    print("Accuracy:", acc)
    print("Classification Report:\n", classification_report(y_true, y_pred))

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.savefig(f'{name.lower()}_confusion_matrix.png')
    plt.show()

    # ROC Curve
    y_prob = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(6, 5))
    plt.plot(fpr, tpr, color='blue', label=f'{name} (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f"{name} - ROC Curve")
    plt.legend(loc='lower right')
    plt.savefig(f'{name.lower()}_roc_curve.png')
    plt.show()

    return acc, roc_auc

# -------------------------------
# 8. Evaluate Models
# -------------------------------
svm_acc, svm_auc = evaluate_model("SVM", y_test, svm_pred, svm_model)
dt_acc, dt_auc = evaluate_model("Decision Tree", y_test, dt_pred, dt_model)

# -------------------------------
# 9. Feature Importance Plots
# -------------------------------
# Decision Tree Feature Importance
dt_importances = pd.Series(dt_model.feature_importances_, index=X.columns)
dt_top10 = dt_importances.sort_values(ascending=False).head(10)

plt.figure(figsize=(8, 5))
sns.barplot(x=dt_top10.values, y=dt_top10.index, palette='viridis')
plt.title("Top 10 Important Features - Decision Tree")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.savefig('decision_tree_feature_importance.png')
plt.show()

# SVM Feature Importance (absolute coefficients)
svm_importances = pd.Series(abs(svm_model.coef_[0]), index=X.columns)
svm_top10 = svm_importances.sort_values(ascending=False).head(10)

plt.figure(figsize=(8, 5))
sns.barplot(x=svm_top10.values, y=svm_top10.index, palette='mako')
plt.title("Top 10 Important Features - SVM")
plt.xlabel("Coefficient Magnitude")
plt.ylabel("Feature")
plt.savefig('svm_feature_importance.png')
plt.show()

# -------------------------------
# 10. Model Comparison Charts
# -------------------------------
comparison = pd.DataFrame({
    'Model': ['SVM', 'Decision Tree'],
    'Accuracy': [svm_acc, dt_acc],
    'AUC Score': [svm_auc, dt_auc]
})

print("\n--- Model Comparison Summary ---")
print(comparison)

# Accuracy Comparison
plt.figure(figsize=(6, 4))
sns.barplot(x='Model', y='Accuracy', data=comparison, palette='coolwarm')
plt.title("Model Accuracy Comparison")
plt.ylim(0.8, 1.0)
plt.savefig('model_accuracy_comparison.png')
plt.show()

# AUC Comparison
plt.figure(figsize=(6, 4))
sns.barplot(x='Model', y='AUC Score', data=comparison, palette='crest')
plt.title("Model AUC Comparison")
plt.ylim(0.8, 1.0)
plt.savefig('model_auc_comparison.png')
plt.show()

# -------------------------------
# 11. Decision Tree Visualization
# -------------------------------
plt.figure(figsize=(20, 10))
plot_tree(dt_model, filled=True, feature_names=X.columns, class_names=['Benign', 'Malignant'])
plt.title("Decision Tree Visualization")
plt.savefig('decision_tree_visualization.png')
plt.show()

